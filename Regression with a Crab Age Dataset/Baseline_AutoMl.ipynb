{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dfac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\ag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dddf818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb2d872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.5250</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>28.973189</td>\n",
       "      <td>12.728926</td>\n",
       "      <td>6.647958</td>\n",
       "      <td>8.348928</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>10.418441</td>\n",
       "      <td>4.521745</td>\n",
       "      <td>2.324659</td>\n",
       "      <td>3.401940</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1.3875</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>24.777463</td>\n",
       "      <td>11.339800</td>\n",
       "      <td>5.556502</td>\n",
       "      <td>6.662133</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>1.4125</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>50.660556</td>\n",
       "      <td>20.354941</td>\n",
       "      <td>10.991839</td>\n",
       "      <td>14.996885</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>23.289114</td>\n",
       "      <td>11.977664</td>\n",
       "      <td>4.507570</td>\n",
       "      <td>5.953395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n",
       "0   0   I  1.5250    1.1750  0.3750  28.973189       12.728926   \n",
       "1   1   I  1.1000    0.8250  0.2750  10.418441        4.521745   \n",
       "2   2   M  1.3875    1.1125  0.3750  24.777463       11.339800   \n",
       "3   3   F  1.7000    1.4125  0.5000  50.660556       20.354941   \n",
       "4   4   I  1.2500    1.0125  0.3375  23.289114       11.977664   \n",
       "\n",
       "   Viscera Weight  Shell Weight  Age  \n",
       "0        6.647958      8.348928    9  \n",
       "1        2.324659      3.401940    8  \n",
       "2        5.556502      6.662133    9  \n",
       "3       10.991839     14.996885   11  \n",
       "4        4.507570      5.953395    8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ed3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "id1, label = 'id','Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff044175",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9978ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230530_092019\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230530_092019\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    74051\n",
      "Train Data Columns: 8\n",
      "Label Column: Age\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 28) unique label values:  [9, 8, 11, 10, 12, 7, 5, 14, 6, 13]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 28\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9673.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.44 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 7 | ['Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight', ...]\n",
      "\t\t('object', []) : 1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Sex']\n",
      "\t\t('float', [])    : 7 | ['Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.22 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.033760516400858864, Train Rows: 71551, Val Rows: 2500\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.7704\t = Validation score   (-mean_absolute_error)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.8028\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\tException occured in `Recorder` when calling event `after_batch`:\n",
      "\t==:\n",
      "7168\n",
      "256\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1502, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1447, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 703, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 308, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params['lr'], cbs=callbacks)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 264, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 253, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 248, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 235, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 201, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastcore\\foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastcore\\basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastcore\\basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\callback\\core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\callback\\core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 560, in after_batch\n",
      "    for met in mets: met.accumulate(self.learn)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\learner.py\", line 482, in accumulate\n",
      "    self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\metrics.py\", line 287, in mae\n",
      "    inp,targ = flatten_check(inp,targ)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastai\\torch_core.py\", line 787, in flatten_check\n",
      "    test_eq(len(inp), len(targ))\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastcore\\test.py\", line 37, in test_eq\n",
      "    test(a,b,equals, cname='==')\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\fastcore\\test.py\", line 27, in test\n",
      "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
      "AssertionError: Exception occured in `Recorder` when calling event `after_batch`:\n",
      "\t==:\n",
      "7168\n",
      "256\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\tcannot reshape array of size 70000 into shape (27,newaxis)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1502, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1447, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 703, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 185, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\engine.py\", line 299, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3271, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3272, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3809, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 55, in function_template\n",
      "    y_hat = y_hat.reshape(len(np.unique(y_true)), -1)\n",
      "ValueError: cannot reshape array of size 70000 into shape (27,newaxis)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\tcannot reshape array of size 70000 into shape (27,newaxis)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1502, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1447, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 703, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 185, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\engine.py\", line 299, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3271, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3272, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3809, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 55, in function_template\n",
      "    y_hat = y_hat.reshape(len(np.unique(y_true)), -1)\n",
      "ValueError: cannot reshape array of size 70000 into shape (27,newaxis)\n",
      "Fitting model: RandomForestGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 168 due to low memory. Expected memory usage reduced from 26.66% -> 15.0% of available memory...\n",
      "\t-1.5092\t = Validation score   (-mean_absolute_error)\n",
      "\t5.76s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 159 due to low memory. Expected memory usage reduced from 28.19% -> 15.0% of available memory...\n",
      "\t-1.528\t = Validation score   (-mean_absolute_error)\n",
      "\t7.96s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-1.4508\t = Validation score   (-mean_absolute_error)\n",
      "\t2414.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 176 due to low memory. Expected memory usage reduced from 25.52% -> 15.0% of available memory...\n",
      "\t-1.5444\t = Validation score   (-mean_absolute_error)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 163 due to low memory. Expected memory usage reduced from 27.6% -> 15.0% of available memory...\n",
      "\t-1.5496\t = Validation score   (-mean_absolute_error)\n",
      "\t3.15s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-1.4716\t = Validation score   (-mean_absolute_error)\n",
      "\t40.66s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.4396\t = Validation score   (-mean_absolute_error)\n",
      "\t319.66s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training... Skipping this model.\n",
      "\t\tcannot reshape array of size 70000 into shape (27,newaxis)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1502, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1447, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 703, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 185, in _fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\engine.py\", line 299, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3271, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3272, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\lightgbm\\basic.py\", line 3809, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"D:\\anaconda\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 55, in function_template\n",
      "    y_hat = y_hat.reshape(len(np.unique(y_true)), -1)\n",
      "ValueError: cannot reshape array of size 70000 into shape (27,newaxis)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-1.4368\t = Validation score   (-mean_absolute_error)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2817.24s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230530_092019\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,eval_metric='mean_absolute_error').fit(\n",
    "            train_data.drop(columns=[id1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e197d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230530_143558\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230530_143558\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    74051\n",
      "Train Data Columns: 8\n",
      "Label Column: Age\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9675.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.44 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 7 | ['Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight', ...]\n",
      "\t\t('object', []) : 1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Sex']\n",
      "\t\t('float', [])    : 7 | ['Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.22 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.033760516400858864, Train Rows: 71551, Val Rows: 2500\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.5109\t = Validation score   (-mean_absolute_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.5302\t = Validation score   (-mean_absolute_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 1.33922\n",
      "[2000]\tvalid_set's l1: 1.33705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.3363\t = Validation score   (-mean_absolute_error)\n",
      "\t9.79s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-1.3292\t = Validation score   (-mean_absolute_error)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-1.403\t = Validation score   (-mean_absolute_error)\n",
      "\t24.56s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-1.3343\t = Validation score   (-mean_absolute_error)\n",
      "\t65.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-1.3677\t = Validation score   (-mean_absolute_error)\n",
      "\t4.89s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-1.3414\t = Validation score   (-mean_absolute_error)\n",
      "\t109.29s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-1.3066\t = Validation score   (-mean_absolute_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.3114\t = Validation score   (-mean_absolute_error)\n",
      "\t150.54s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-1.3284\t = Validation score   (-mean_absolute_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-1.2969\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 373.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230530_143558\\\")\n"
     ]
    }
   ],
   "source": [
    "#需要指定为Regression问题\n",
    "predictor = TabularPredictor(label=label,eval_metric='mean_absolute_error',problem_type='regression').fit(\n",
    "            train_data.drop(columns=[id1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c285b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: data/test.csv | Columns = 9 / 9 | Rows = 49368 -> 49368\n"
     ]
    }
   ],
   "source": [
    "test_data = TabularDataset('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7c6a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(test_data.drop(columns=[id1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfe0af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74051</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>8.618248</td>\n",
       "      <td>3.657085</td>\n",
       "      <td>1.729319</td>\n",
       "      <td>2.721552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74052</td>\n",
       "      <td>I</td>\n",
       "      <td>1.1625</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>15.507176</td>\n",
       "      <td>7.030676</td>\n",
       "      <td>3.246018</td>\n",
       "      <td>3.968930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74053</td>\n",
       "      <td>F</td>\n",
       "      <td>1.2875</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>14.571643</td>\n",
       "      <td>5.556502</td>\n",
       "      <td>3.883882</td>\n",
       "      <td>4.819415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74054</td>\n",
       "      <td>F</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>28.377849</td>\n",
       "      <td>13.380964</td>\n",
       "      <td>6.548735</td>\n",
       "      <td>7.030676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74055</td>\n",
       "      <td>I</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>11.765042</td>\n",
       "      <td>5.528153</td>\n",
       "      <td>2.466407</td>\n",
       "      <td>3.331066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n",
       "0  74051   I  1.0500    0.7625  0.2750   8.618248        3.657085   \n",
       "1  74052   I  1.1625    0.8875  0.2750  15.507176        7.030676   \n",
       "2  74053   F  1.2875    0.9875  0.3250  14.571643        5.556502   \n",
       "3  74054   F  1.5500    0.9875  0.3875  28.377849       13.380964   \n",
       "4  74055   I  1.1125    0.8500  0.2625  11.765042        5.528153   \n",
       "\n",
       "   Viscera Weight  Shell Weight  \n",
       "0        1.729319      2.721552  \n",
       "1        3.246018      3.968930  \n",
       "2        3.883882      4.819415  \n",
       "3        6.548735      7.030676  \n",
       "4        2.466407      3.331066  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw = pd.read_csv('data/test.csv')\n",
    "test_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda1965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':test_data_raw.id,'Age':preds}).set_index('id').to_csv('crab_automl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1d586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ac171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ag]",
   "language": "python",
   "name": "conda-env-ag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
